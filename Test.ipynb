{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64e8423-696e-40f8-af48-051a8472a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "import albumentations\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from torchmetrics import F1\n",
    "from pytorch_toolbelt import losses as L\n",
    "import timm\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "gpu = 1 if torch.cuda.is_available() else 0\n",
    "print(f'Using {gpu} GPUS')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e11592-63f3-4c6d-b69f-a46eba289dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('List_train.csv')\n",
    "df_val = pd.read_csv('List_val.csv')\n",
    "df_test = pd.read_csv('List_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5c2b79-f6bb-4903-96df-87924460c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://juansensio.com/blog/062_multihead_attention\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mode, df):\n",
    "        self.mode = mode\n",
    "        self.df = df \n",
    "        self.mean_img = (0.485, 0.456, 0.406 )\n",
    "        self.std_img = (0.229, 0.224, 0.225)\n",
    "        self.classes = ['Pinus','Erica.m', 'Cistus sp', 'Lavandula', 'Citrus sp', 'Helianthus annuus',\n",
    "                        'Eucalyptus sp.', 'Rosmarinus officinalis', 'Brassica', 'Cardus', 'Tilia', 'Taraxacum']\n",
    "    def __crop_padding(self,img):\n",
    "        ## convert to gray\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ## set threshold for 0\n",
    "        _,thresh = cv2.threshold(img_gray,10,255,cv2.THRESH_BINARY)\n",
    "        ## find contours\n",
    "        contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        crop = img[y:y+h,x:x+w,:]\n",
    "        return crop\n",
    "    def __getitem__(self, index):\n",
    "        name_img = self.df['name'].iloc[index]\n",
    "        label    = self.df['labels'].iloc[index]\n",
    "        ## READ IMAGE\n",
    "        image = plt.imread(name_img)\n",
    "        image = self.__crop_padding(image)\n",
    "        target = torch.tensor(self.classes.index(label))\n",
    "        # print(f'Image shape: {image.shape} \\t Target:{target}')\n",
    "        if self.mode=='train':\n",
    "            train_augm = albumentations.Compose(\n",
    "              [\n",
    "               albumentations.Resize(height=320,width=320),\n",
    "               albumentations.Normalize(self.mean_img, self.std_img, max_pixel_value=255.0, always_apply=True),\n",
    "              #  albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "              #  albumentations.Flip(p=0.5)\n",
    "              ]\n",
    "            )\n",
    "            transformed = train_augm(image=image)\n",
    "            image=transformed['image']\n",
    "        else:\n",
    "            valid_augm = albumentations.Compose(\n",
    "              [\n",
    "               albumentations.Resize(height=320,width=320),\n",
    "               albumentations.Normalize(self.mean_img, self.std_img, max_pixel_value=255.0, always_apply=True)\n",
    "              ]\n",
    "            )\n",
    "            transformed = valid_augm(image=image)\n",
    "            image=transformed['image']\n",
    "        image = torch.from_numpy(image.transpose()).float()\n",
    "        target_oh = torch.nn.functional.one_hot(target, num_classes=12).float()\n",
    "        data = {\"image\":image,\n",
    "                \"target_oh\":target_oh,\n",
    "                'target':target,\n",
    "                'class_name':label } \n",
    "        # print(f'Image shape: {image.shape} \\t Target:{target}')\n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "class HoneyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 4, Dataset = Dataset):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.Dataset = Dataset\n",
    "        # self.train_ds =  self.Dataset(mode='train',df= df_train)\n",
    "        # self.val_ds   =  self.Dataset(mode='val', df= df_val)\n",
    "        self.test_ds   =  self.Dataset(mode='test', df= df_test)\n",
    "    # def train_dataloader(self):\n",
    "    #     return DataLoader(self.train_ds,\n",
    "    #                       batch_size=4,\n",
    "    #                       # shuffle=True,\n",
    "    #                       num_workers=0,\n",
    "    #                       pin_memory=True,\n",
    "    #                       drop_last=True,\n",
    "    #                       # sampler=sampler\n",
    "    #                       )\n",
    "    # def val_dataloader(self):\n",
    "    #     return DataLoader(self.val_ds, batch_size=4, shuffle=False, num_workers=0, pin_memory=True, drop_last=True )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False )\n",
    "    \n",
    "dm = HoneyDataModule(Dataset=Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80562354-ca34-4778-af7f-fbe3752e4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MatthewsCorrcoef as MCC\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea7430e-4108-4174-8b18-6c9d03d9e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss_CE, val_epoch_acc_CE = [], []\n",
    "train_epoch_loss_CE, train_epoch_acc_CE = [], []\n",
    "\n",
    "class LitModel_Focal(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__( )\n",
    "        # self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        # self.class_weights=class_weights.to('cuda')\n",
    "        self.focal_loss = L.FocalLoss(alpha=0.25, gamma=2)\n",
    "        # self.class_weights\n",
    "        self.f1_score = F1(num_classes=12,average='weighted')\n",
    "        self.mcc = MCC(num_classes=12)\n",
    "        self.auroc = AUROC(num_classes=12,average='weighted')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self(x)\n",
    "            return torch.argmax(y_hat, axis=1)\n",
    "#     def compute_loss_and_metrics(self, batch):\n",
    "#         x, y = batch['image'], batch['target']\n",
    "#         # print(f'X: {x.shape} \\t Y: {y.shape}')\n",
    "#         y_hat = self(x)\n",
    "#         # print(f'Output: {y_hat.shape}')\n",
    "#         # loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "#         loss = self.focal_loss(y_hat, y)\n",
    "#         # acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.shape[0]\n",
    "#         # y1 = y.detach().cpu().numpy()\n",
    "#         # # print(y1.shape)\n",
    "#         mcc = self.mcc(y_hat, y)\n",
    "#         auroc = self.auroc(y_hat, y)\n",
    "#         y_hat1 = torch.argmax(y_hat, axis=1)\n",
    "#         # y_hat1 = y_hat1.detach().cpu().numpy()\n",
    "#         # print(y_hat1.shape)\n",
    "#         f1w = self.f1_score( y, y_hat1)#, average='weighted')\n",
    "#         return loss, f1w, mcc, auroc\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         loss, f1w, mcc = self.compute_loss_and_metrics(batch)\n",
    "#         self.log('train_loss', loss)\n",
    "#         self.log('train_F1w', f1w, prog_bar=True)\n",
    "#         self.log('train_mcc', mcc, prog_bar=True)\n",
    "#         self.log('train_auroc', auroc, prog_bar=True)\n",
    "#         #print(f'Training_step: loss> {loss} acc:{acc}')\n",
    "#         return {'loss':loss,'f1w':torch.tensor(f1w), 'mcc':torch.tensor(mcc), 'auroc':torch.tensor(auroc)}\n",
    "    \n",
    "#     def training_epoch_end(self, outputs):\n",
    "#         avg_train_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "#         avg_train_f1w  = torch.stack([x['f1w'] for x in outputs]).mean()\n",
    "#         avg_train_mcc  = torch.stack([x['mcc'] for x in outputs]).mean()\n",
    "#         avg_train_auroc  = torch.stack([x['auroc'] for x in outputs]).mean()\n",
    "\n",
    "#         train_epoch_loss_CE.append(avg_train_loss.item())\n",
    "#         train_epoch_acc_CE.append(avg_train_f1w.item())\n",
    "#         #print(f'Epoch {self.current_epoch} TrainLOSS:{avg_train_loss} TrainACC:{avg_train_acc}  ')\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         loss, f1w, mcc, auroc = self.compute_loss_and_metrics(batch)\n",
    "#         self.log('val_loss', loss, prog_bar=True)\n",
    "#         self.log('val_f1w', f1w, prog_bar=True)\n",
    "#         self.log('val_mcc', mcc, prog_bar=True)\n",
    "#         self.log('val_auroc', auroc, prog_bar=True)\n",
    "        \n",
    "#         return {'val_loss': torch.tensor(loss.item()), 'val_f1w': torch.tensor(f1w), 'val_mcc': torch.tensor(mcc), 'val_auroc': torch.tensor(auroc) }\n",
    "#     def validation_epoch_end(self, outputs):\n",
    "#         avg_val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "#         avg_val_f1w  = torch.stack([x['val_f1w'] for x in outputs]).mean()\n",
    "#         avg_val_mcc  = torch.stack([x['val_mcc'] for x in outputs]).mean()\n",
    "#         avg_val_auroc  = torch.stack([x['val_auroc'] for x in outputs]).mean()\n",
    "        \n",
    "#         self.log('EarlyStop_Log', avg_val_loss.detach(), on_epoch=True, sync_dist=True)\n",
    "#         self.log('avg_val_f1w', avg_val_f1w.detach(), on_epoch=True, sync_dist=True)\n",
    "#         self.log('avg_val_mcc', avg_val_mcc.detach(), on_epoch=True, sync_dist=True)\n",
    "#         self.log('avg_val_auroc', avg_val_auroc.detach(), on_epoch=True, sync_dist=True)\n",
    "        \n",
    "#         val_epoch_loss_CE.append(avg_val_loss.item())\n",
    "#         val_epoch_acc_CE.append(avg_val_f1w.item())\n",
    "#         #print(f'VAL-Epoch {self.current_epoch} LOSS:{avg_val_loss} ACC:{avg_val_acc} ')\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "#                                                                     T_0=10,\n",
    "#                                                                     T_mult=1,\n",
    "#                                                                     eta_min=1e-7,\n",
    "#                                                                     verbose=True,\n",
    "#                                                                     )\n",
    "\n",
    "#         # lr_scheduler = {'scheduler': MultiStepLR(optimizer, milestones=[10,20,30,40], gamma=0.5,),'interval': 'epoch','frequency':1}\n",
    "#         return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278e369-a6c6-4f0e-adde-4c61d7dc0286",
   "metadata": {},
   "source": [
    "## Probando EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151905d8-8363-45b6-83bf-90eae0a913a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)\n",
    "# eff_model = timm.create_model('tf_efficientnet_b7',pretrained='True',num_classes=12)\n",
    "eff_model = timm.create_model('densenet121',pretrained='True',num_classes=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe48bc9-27c4-4443-a81e-87838bf84776",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_model_focal_sampler  = LitModel_Focal(model=eff_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9776df2e-7ccb-47fe-909b-dbf43334483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best-epoch=11-val_loss=0.04-avg_val_f1w=0.95.ckpt'   pngs    wandb\n",
      " ious\t\t\t\t\t\t      preds\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/Honey_densenet121/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4dfc25-d131-4ca6-925a-b88f3ef119af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Pinus       0.00      0.00      0.00        28\n",
      "               Erica.m       0.87      0.32      0.47       184\n",
      "             Cistus sp       0.10      0.72      0.18        69\n",
      "             Lavandula       0.00      0.00      0.00        74\n",
      "             Citrus sp       0.00      0.00      0.00        53\n",
      "     Helianthus annuus       0.99      0.80      0.88        91\n",
      "        Eucalyptus sp.       0.00      0.00      0.00        95\n",
      "Rosmarinus officinalis       0.00      0.00      0.00        52\n",
      "              Brassica       0.32      0.48      0.38       140\n",
      "                Cardus       0.12      0.32      0.17        19\n",
      "                 Tilia       0.00      0.00      0.00        67\n",
      "             Taraxacum       0.40      0.08      0.13        25\n",
      "\n",
      "              accuracy                           0.29       897\n",
      "             macro avg       0.23      0.23      0.18       897\n",
      "          weighted avg       0.35      0.29      0.27       897\n",
      "\n",
      "CPU times: user 26.9 s, sys: 1.41 s, total: 28.3 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"Honey_densenet121/Best-epoch=11-val_loss=0.04-avg_val_f1w=0.95.ckpt\"\n",
    "baseline_model  = LitModel_Focal(model=eff_model)\n",
    "\n",
    "\n",
    "checkpoint =  torch.load('/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/'+ model_name)\n",
    "\n",
    "baseline_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "targets, preds = [],[]\n",
    "baseline_model.to('cuda')\n",
    "for ii, data in enumerate(dm.test_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        targets.append(data['target'].numpy()) #torch.argmax(data['target'],dim=1).numpy()\n",
    "        # y = y.reshape((-1,1))\n",
    "        # print(y.shape)\n",
    "        ## inference\n",
    "        o = baseline_model.predict(data['image'].to('cuda')).cpu().numpy()\n",
    "        # print(o.shape)\n",
    "        preds.append(o)\n",
    "        # print(y)\n",
    "        # print(o)\n",
    "        # if ii==2:\n",
    "        #   break\n",
    "print(ii)\n",
    "preds2 = np.vstack([x for x in preds]).reshape(-1,1)\n",
    "targets2 = np.vstack([x for x in targets]).reshape(-1,1)\n",
    "target_names = ['Pinus','Erica.m', 'Cistus sp', 'Lavandula', 'Citrus sp', 'Helianthus annuus',\n",
    "          'Eucalyptus sp.', 'Rosmarinus officinalis', 'Brassica', 'Cardus', 'Tilia', 'Taraxacum']\n",
    "\n",
    "print(classification_report(targets2, preds2, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266e542-3cad-40d8-a7d1-7a0dfb2417ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39706687-7920-4cd7-a354-d26726a01fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a8eea-4efa-467b-934d-c434880d6f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c85b88-a03a-4307-9ce1-adef0742264b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
