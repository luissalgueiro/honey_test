{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64e8423-696e-40f8-af48-051a8472a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "import albumentations\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from torchmetrics import F1\n",
    "from pytorch_toolbelt import losses as L\n",
    "import timm\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "gpu = 1 if torch.cuda.is_available() else 0\n",
    "print(f'Using {gpu} GPUS')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da888e3-d6c7-4355-b766-14eed6f0e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eucalyptus sp.', 'Brassica', 'Taraxacum', 'Rosmarinus officinalis', 'Tilia', 'Erica.m', 'Lavandula', 'Cistus sp', 'Pinus', 'Cardus', 'Citrus sp', 'Helianthus annuus']\n"
     ]
    }
   ],
   "source": [
    "root_path = '/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/datasets/'\n",
    "print(os.listdir(root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50fdc5e-9ca7-4f08-bd3d-5618bce52a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('List_train.csv')\n",
    "df_val = pd.read_csv('List_val.csv')\n",
    "df_test = pd.read_csv('List_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da9842e-6346-4e9f-950e-4525cc07c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>weights</th>\n",
       "      <th>weights_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brassica</th>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.029288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardus</th>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.217930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cistus sp</th>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.059570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Citrus sp</th>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.078494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erica.m</th>\n",
       "      <td>1576</td>\n",
       "      <td>1576</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.022263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eucalyptus sp.</th>\n",
       "      <td>807</td>\n",
       "      <td>807</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helianthus annuus</th>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.044983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lavandula</th>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.055168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pinus</th>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.145588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rosmarinus officinalis</th>\n",
       "      <td>444</td>\n",
       "      <td>444</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.079024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taraxacum</th>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.163194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tilia</th>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.061020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Unnamed: 0  name   weights weights_norm\n",
       "                            count count                       \n",
       "labels                                                        \n",
       "Brassica                     1198  1198  0.000851     0.029288\n",
       "Cardus                        161   161  0.006335     0.217930\n",
       "Cistus sp                     589   589  0.001732     0.059570\n",
       "Citrus sp                     447   447  0.002282     0.078494\n",
       "Erica.m                      1576  1576  0.000647     0.022263\n",
       "Eucalyptus sp.                807   807  0.001264     0.043478\n",
       "Helianthus annuus             780   780  0.001308     0.044983\n",
       "Lavandula                     636   636  0.001604     0.055168\n",
       "Pinus                         241   241  0.004232     0.145588\n",
       "Rosmarinus officinalis        444   444  0.002297     0.079024\n",
       "Taraxacum                     215   215  0.004744     0.163194\n",
       "Tilia                         575   575  0.001774     0.061020"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train = df_train.groupby('labels').agg({'count'})\n",
    "count_train['weights'] = 1.02/count_train['name']\n",
    "count_train['weights_norm'] = count_train['weights']/count_train['weights'].sum()\n",
    "# count_train['weights_nor'].sum()\n",
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d19ae7-3b10-4ab1-ac38-9c58e6eafeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1456, 0.0223, 0.0596, 0.0552, 0.0785, 0.0450, 0.0435, 0.0790, 0.0293,\n",
       "        0.2179, 0.0610, 0.1632])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self.classes = ['Pinus','Erica.m', 'Cistus sp', 'Lavandula', 'Citrus sp', 'Helianthus annuus',\n",
    "#                 'Eucalyptus sp.', 'Rosmarinus officinalis', 'Brassica', 'Cardus', 'Tilia', 'Taraxacum']\n",
    "class_weights=torch.Tensor([count_train.loc['Pinus','weights_norm'].item(),\n",
    "                      count_train.loc['Erica.m','weights_norm'].item(),\n",
    "                      count_train.loc['Cistus sp','weights_norm'].item(),\n",
    "                      count_train.loc['Lavandula','weights_norm'].item(),\n",
    "                      count_train.loc['Citrus sp','weights_norm'].item(),\n",
    "                      count_train.loc['Helianthus annuus','weights_norm'].item(),\n",
    "                      count_train.loc['Eucalyptus sp.','weights_norm'].item(),\n",
    "                      count_train.loc['Rosmarinus officinalis','weights_norm'].item(),\n",
    "                      count_train.loc['Brassica','weights_norm'].item(),\n",
    "                      count_train.loc['Cardus','weights_norm'].item(),\n",
    "                      count_train.loc['Tilia','weights_norm'].item(),\n",
    "                      count_train.loc['Taraxacum','weights_norm'].item(),\n",
    "                      ])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaff23d-df70-4df0-95f6-cf9fd90a821f",
   "metadata": {},
   "source": [
    "## Weighted Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508e1392-62ad-4d0b-a9ea-76bdc7621dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7669])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "samples_weight = np.array([count_train.loc[t,'weights_norm'].item() for t in df_train['labels']])\n",
    "samples_weight=torch.from_numpy(samples_weight)\n",
    "\n",
    "print(samples_weight.shape)\n",
    "\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c1647-964b-40c9-bc0e-442b3e8ed7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5c2b79-f6bb-4903-96df-87924460c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://juansensio.com/blog/062_multihead_attention\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mode, df):\n",
    "        self.mode = mode\n",
    "        self.df = df \n",
    "        self.mean_img = (0.485, 0.456, 0.406 )\n",
    "        self.std_img = (0.229, 0.224, 0.225)\n",
    "        self.classes = ['Pinus','Erica.m', 'Cistus sp', 'Lavandula', 'Citrus sp', 'Helianthus annuus',\n",
    "                        'Eucalyptus sp.', 'Rosmarinus officinalis', 'Brassica', 'Cardus', 'Tilia', 'Taraxacum']\n",
    "    def __crop_padding(self,img):\n",
    "        ## convert to gray\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ## set threshold for 0\n",
    "        _,thresh = cv2.threshold(img_gray,10,255,cv2.THRESH_BINARY)\n",
    "        ## find contours\n",
    "        contours, hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnt = contours[0]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        crop = img[y:y+h,x:x+w,:]\n",
    "        return crop\n",
    "    def __getitem__(self, index):\n",
    "        name_img = self.df['name'].iloc[index]\n",
    "        label    = self.df['labels'].iloc[index]\n",
    "        ## READ IMAGE\n",
    "        image = plt.imread(name_img)\n",
    "        image = self.__crop_padding(image)\n",
    "        target = torch.tensor(self.classes.index(label))\n",
    "        # print(f'Image shape: {image.shape} \\t Target:{target}')\n",
    "        if self.mode=='train':\n",
    "            train_augm = albumentations.Compose(\n",
    "              [\n",
    "               albumentations.Resize(height=320,width=320),\n",
    "               albumentations.Normalize(self.mean_img, self.std_img, max_pixel_value=255.0, always_apply=True),\n",
    "              #  albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "              #  albumentations.Flip(p=0.5)\n",
    "              ]\n",
    "            )\n",
    "            transformed = train_augm(image=image)\n",
    "            image=transformed['image']\n",
    "        else:\n",
    "            valid_augm = albumentations.Compose(\n",
    "              [\n",
    "               albumentations.Resize(height=320,width=320),\n",
    "               albumentations.Normalize(self.mean_img, self.std_img, max_pixel_value=255.0, always_apply=True)\n",
    "              ]\n",
    "            )\n",
    "            transformed = valid_augm(image=image)\n",
    "            image=transformed['image']\n",
    "        image = torch.from_numpy(image.transpose()).float()\n",
    "        target_oh = torch.nn.functional.one_hot(target, num_classes=12).float()\n",
    "        data = {\"image\":image,\n",
    "                \"target_oh\":target_oh,\n",
    "                'target':target,\n",
    "                'class_name':label } \n",
    "        # print(f'Image shape: {image.shape} \\t Target:{target}')\n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "class HoneyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 4, Dataset = Dataset):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.Dataset = Dataset\n",
    "        self.train_ds =  self.Dataset(mode='train',df= df_train)\n",
    "        self.val_ds   =  self.Dataset(mode='val', df= df_val)\n",
    "        self.test_ds   =  self.Dataset(mode='test', df= df_test)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds,\n",
    "                          batch_size=4,\n",
    "                          # shuffle=True,\n",
    "                          num_workers=0,\n",
    "                          pin_memory=True,\n",
    "                          drop_last=True,\n",
    "                          sampler=sampler\n",
    "                          )\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=4, shuffle=False, num_workers=0, pin_memory=True, drop_last=True )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False )\n",
    "    \n",
    "dm = HoneyDataModule(Dataset=Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80562354-ca34-4778-af7f-fbe3752e4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MatthewsCorrcoef as MCC\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eea7430e-4108-4174-8b18-6c9d03d9e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch_loss_CE, val_epoch_acc_CE = [], []\n",
    "train_epoch_loss_CE, train_epoch_acc_CE = [], []\n",
    "\n",
    "class LitModel_Focal(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__( )\n",
    "        # self.save_hyperparameters()\n",
    "        self.model = model\n",
    "        # self.class_weights=class_weights.to('cuda')\n",
    "        self.focal_loss = L.FocalLoss(alpha=0.25, gamma=2)\n",
    "        # self.class_weights\n",
    "        self.f1_score = F1(num_classes=12,average='weighted')\n",
    "        # self.mcc = MCC(num_classes=12)\n",
    "        # self.auroc = AUROC(num_classes=12,average='weighted')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            y_hat = self(x)\n",
    "            return y_hat\n",
    "            # return torch.argmax(y_hat, axis=1)\n",
    "    def compute_loss_and_metrics(self, batch):\n",
    "        x, y = batch['image'], batch['target']\n",
    "        # print(f'X: {x.shape} \\t Y: {y.shape}')\n",
    "        y_hat = self(x)\n",
    "        # print(f'Output: {y_hat.shape}')\n",
    "        # loss = F.cross_entropy(y_hat, y, weight=self.class_weights)\n",
    "        loss = self.focal_loss(y_hat, y)\n",
    "        # acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.shape[0]\n",
    "        # y1 = y.detach().cpu().numpy()\n",
    "        # # print(y1.shape)\n",
    "        # mcc = self.mcc(y_hat, y)\n",
    "        # auroc = self.auroc(y_hat, y)\n",
    "        y_hat1 = torch.argmax(y_hat, axis=1)\n",
    "        # y_hat1 = y_hat1.detach().cpu().numpy()\n",
    "        # print(y_hat1.shape)\n",
    "        f1w = self.f1_score( y, y_hat1)#, average='weighted')\n",
    "        return loss, f1w#, mcc, auroc\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, f1w = self.compute_loss_and_metrics(batch)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_F1w', f1w, prog_bar=True)\n",
    "        # self.log('train_mcc', mcc, prog_bar=True)\n",
    "        # self.log('train_auroc', auroc, prog_bar=True)\n",
    "        #print(f'Training_step: loss> {loss} acc:{acc}')\n",
    "        return {'loss':loss,'f1w':torch.tensor(f1w)}#, 'mcc':torch.tensor(mcc), 'auroc':torch.tensor(auroc)}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_train_f1w  = torch.stack([x['f1w'] for x in outputs]).mean()\n",
    "        # avg_train_mcc  = torch.stack([x['mcc'] for x in outputs]).mean()\n",
    "        # avg_train_auroc  = torch.stack([x['auroc'] for x in outputs]).mean()\n",
    "\n",
    "        train_epoch_loss_CE.append(avg_train_loss.item())\n",
    "        train_epoch_acc_CE.append(avg_train_f1w.item())\n",
    "        #print(f'Epoch {self.current_epoch} TrainLOSS:{avg_train_loss} TrainACC:{avg_train_acc}  ')\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, f1w= self.compute_loss_and_metrics(batch)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_f1w', f1w, prog_bar=True)\n",
    "        # self.log('val_mcc', mcc, prog_bar=True)\n",
    "        # self.log('val_auroc', auroc, prog_bar=True)\n",
    "        \n",
    "        return {'val_loss': torch.tensor(loss.item()), 'val_f1w': torch.tensor(f1w)}#, 'val_mcc': torch.tensor(mcc), 'val_auroc': torch.tensor(auroc) }\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_val_f1w  = torch.stack([x['val_f1w'] for x in outputs]).mean()\n",
    "        # avg_val_mcc  = torch.stack([x['val_mcc'] for x in outputs]).mean()\n",
    "        # avg_val_auroc  = torch.stack([x['val_auroc'] for x in outputs]).mean()\n",
    "        \n",
    "        self.log('EarlyStop_Log', avg_val_loss.detach(), on_epoch=True, sync_dist=True)\n",
    "        self.log('avg_val_f1w', avg_val_f1w.detach(), on_epoch=True, sync_dist=True)\n",
    "        # self.log('avg_val_mcc', avg_val_mcc.detach(), on_epoch=True, sync_dist=True)\n",
    "        # self.log('avg_val_auroc', avg_val_auroc.detach(), on_epoch=True, sync_dist=True)\n",
    "        \n",
    "        val_epoch_loss_CE.append(avg_val_loss.item())\n",
    "        val_epoch_acc_CE.append(avg_val_f1w.item())\n",
    "        #print(f'VAL-Epoch {self.current_epoch} LOSS:{avg_val_loss} ACC:{avg_val_acc} ')\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                                    T_0=10,\n",
    "                                                                    T_mult=1,\n",
    "                                                                    eta_min=1e-7,\n",
    "                                                                    verbose=True,\n",
    "                                                                    )\n",
    "\n",
    "        # lr_scheduler = {'scheduler': MultiStepLR(optimizer, milestones=[10,20,30,40], gamma=0.5,),'interval': 'epoch','frequency':1}\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278e369-a6c6-4f0e-adde-4c61d7dc0286",
   "metadata": {},
   "source": [
    "## Probando EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "151905d8-8363-45b6-83bf-90eae0a913a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)\n",
    "eff_model = timm.create_model('tf_efficientnet_b7',pretrained='True',num_classes=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe48bc9-27c4-4443-a81e-87838bf84776",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_model_focal_sampler  = LitModel_Focal(model=eff_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08da91de-025d-4fc7-afb5-5c2fabf4f99e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name       | Type         | Params\n",
      "--------------------------------------------\n",
      "0 | model      | EfficientNet | 63.8 M\n",
      "1 | focal_loss | FocalLoss    | 0     \n",
      "2 | f1_score   | F1           | 0     \n",
      "--------------------------------------------\n",
      "63.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "63.8 M    Total params\n",
      "255.271   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0: adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 0:  95%|█████████▍| 1916/2018 [07:22<00:23,  4.33it/s, loss=0.0508, v_num=1666580, train_F1w=1.000]Epoch     1: adjusting learning rate of group 0 to 9.7555e-05.\n",
      "Epoch 0:  95%|█████████▍| 1917/2018 [07:22<00:23,  4.33it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 1919/2018 [07:22<00:22,  4.33it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  95%|█████████▌| 1921/2018 [07:22<00:22,  4.34it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  95%|█████████▌| 1923/2018 [07:23<00:21,  4.34it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  95%|█████████▌| 1925/2018 [07:23<00:21,  4.34it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  95%|█████████▌| 1927/2018 [07:23<00:20,  4.35it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1929/2018 [07:23<00:20,  4.35it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1931/2018 [07:23<00:19,  4.35it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1933/2018 [07:23<00:19,  4.36it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1935/2018 [07:23<00:19,  4.36it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1937/2018 [07:24<00:18,  4.36it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1939/2018 [07:24<00:18,  4.37it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▌| 1941/2018 [07:24<00:17,  4.37it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▋| 1943/2018 [07:24<00:17,  4.37it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▋| 1945/2018 [07:24<00:16,  4.37it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  96%|█████████▋| 1947/2018 [07:24<00:16,  4.38it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1949/2018 [07:24<00:15,  4.38it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1951/2018 [07:25<00:15,  4.38it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1953/2018 [07:25<00:14,  4.39it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1955/2018 [07:25<00:14,  4.39it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1957/2018 [07:25<00:13,  4.39it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1959/2018 [07:25<00:13,  4.40it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1961/2018 [07:25<00:12,  4.40it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1963/2018 [07:25<00:12,  4.40it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1965/2018 [07:26<00:12,  4.41it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  97%|█████████▋| 1967/2018 [07:26<00:11,  4.41it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1969/2018 [07:26<00:11,  4.41it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1971/2018 [07:26<00:10,  4.41it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1973/2018 [07:26<00:10,  4.42it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1975/2018 [07:26<00:09,  4.42it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1977/2018 [07:26<00:09,  4.42it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1979/2018 [07:27<00:08,  4.43it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1981/2018 [07:27<00:08,  4.43it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1983/2018 [07:27<00:07,  4.43it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1985/2018 [07:27<00:07,  4.44it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  98%|█████████▊| 1987/2018 [07:27<00:06,  4.44it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▊| 1989/2018 [07:27<00:06,  4.44it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▊| 1991/2018 [07:27<00:06,  4.44it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 1993/2018 [07:28<00:05,  4.45it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 1995/2018 [07:28<00:05,  4.45it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 1997/2018 [07:28<00:04,  4.45it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 1999/2018 [07:28<00:04,  4.46it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 2001/2018 [07:28<00:03,  4.46it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 2003/2018 [07:28<00:03,  4.46it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 2005/2018 [07:28<00:02,  4.47it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0:  99%|█████████▉| 2007/2018 [07:29<00:02,  4.47it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|█████████▉| 2009/2018 [07:29<00:02,  4.47it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|█████████▉| 2011/2018 [07:29<00:01,  4.48it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|█████████▉| 2013/2018 [07:29<00:01,  4.48it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|█████████▉| 2015/2018 [07:29<00:00,  4.48it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|█████████▉| 2017/2018 [07:29<00:00,  4.48it/s, loss=0.0503, v_num=1666580, train_F1w=1.000]\n",
      "Epoch 0: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.0503, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 0: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.0503, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1916: avg_val_f1w reached 0.96700 (best 0.96700), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/EffB7-Focal-Sampler-epoch=0-val_loss=0.03-avg_val_f1w=0.97-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0253, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967] Epoch     2: adjusting learning rate of group 0 to 9.0460e-05.\n",
      "Epoch 1:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.35it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  95%|█████████▌| 1924/2018 [07:21<00:21,  4.35it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.36it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1938/2018 [07:22<00:18,  4.38it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1940/2018 [07:22<00:17,  4.38it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.39it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.39it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1952/2018 [07:23<00:15,  4.40it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1954/2018 [07:23<00:14,  4.40it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.41it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.42it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1968/2018 [07:24<00:11,  4.42it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.43it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.44it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.44it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1982/2018 [07:25<00:08,  4.44it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.45it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.46it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.46it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 1996/2018 [07:26<00:04,  4.47it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.48it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.48it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|█████████▉| 2010/2018 [07:27<00:01,  4.49it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.50it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0343, val_f1w=0.967]\n",
      "Epoch 1: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 1: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0258, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 3833: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  95%|█████████▍| 1916/2018 [07:20<00:23,  4.35it/s, loss=0.0207, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953] Epoch     3: adjusting learning rate of group 0 to 7.9410e-05.\n",
      "Epoch 2:  95%|█████████▌| 1918/2018 [07:20<00:22,  4.35it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.36it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  95%|█████████▌| 1924/2018 [07:21<00:21,  4.36it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  95%|█████████▌| 1926/2018 [07:21<00:21,  4.36it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1928/2018 [07:21<00:20,  4.36it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1930/2018 [07:21<00:20,  4.37it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.38it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1938/2018 [07:22<00:18,  4.38it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1940/2018 [07:22<00:17,  4.38it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▌| 1942/2018 [07:22<00:17,  4.39it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▋| 1944/2018 [07:22<00:16,  4.39it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.40it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.40it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1952/2018 [07:23<00:14,  4.40it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1954/2018 [07:23<00:14,  4.41it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1956/2018 [07:23<00:14,  4.41it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1958/2018 [07:23<00:13,  4.41it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.42it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.42it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1968/2018 [07:24<00:11,  4.43it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1970/2018 [07:24<00:10,  4.43it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1972/2018 [07:24<00:10,  4.43it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1974/2018 [07:24<00:09,  4.44it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.44it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.45it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1982/2018 [07:25<00:08,  4.45it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1984/2018 [07:25<00:07,  4.45it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  98%|█████████▊| 1986/2018 [07:25<00:07,  4.45it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▊| 1988/2018 [07:25<00:06,  4.46it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.46it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.47it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 1996/2018 [07:26<00:04,  4.47it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 1998/2018 [07:26<00:04,  4.47it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 2000/2018 [07:26<00:04,  4.48it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 2002/2018 [07:26<00:03,  4.48it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.49it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.49it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|█████████▉| 2010/2018 [07:27<00:01,  4.49it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|█████████▉| 2012/2018 [07:27<00:01,  4.49it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|█████████▉| 2014/2018 [07:27<00:00,  4.50it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|█████████▉| 2016/2018 [07:27<00:00,  4.50it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0514, val_f1w=0.953]\n",
      "Epoch 2: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 2: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 5750: avg_val_f1w reached 0.97030 (best 0.97030), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/EffB7-Focal-Sampler-epoch=2-val_loss=0.03-avg_val_f1w=0.97.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.00841, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]Epoch     4: adjusting learning rate of group 0 to 6.5485e-05.\n",
      "Epoch 3:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.35it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  95%|█████████▌| 1924/2018 [07:21<00:21,  4.35it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  95%|█████████▌| 1926/2018 [07:21<00:21,  4.36it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1938/2018 [07:22<00:18,  4.38it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1940/2018 [07:22<00:17,  4.38it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.39it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.39it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1952/2018 [07:23<00:15,  4.40it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1954/2018 [07:23<00:14,  4.40it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.41it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.42it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1968/2018 [07:24<00:11,  4.42it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.43it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.44it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.44it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1982/2018 [07:25<00:08,  4.44it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.45it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.46it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.46it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 1996/2018 [07:26<00:04,  4.47it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.48it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|█████████▉| 2010/2018 [07:27<00:01,  4.49it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.50it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0324, val_f1w=0.970]\n",
      "Epoch 3: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 3: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00426, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 7667: avg_val_f1w reached 0.98845 (best 0.98845), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/EffB7-Focal-Sampler-epoch=3-val_loss=0.01-avg_val_f1w=0.99.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0183, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988] Epoch     5: adjusting learning rate of group 0 to 5.0050e-05.\n",
      "Epoch 4:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.35it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  95%|█████████▌| 1924/2018 [07:21<00:21,  4.35it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  95%|█████████▌| 1926/2018 [07:21<00:21,  4.36it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1938/2018 [07:22<00:18,  4.38it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1940/2018 [07:22<00:17,  4.38it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.39it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.40it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1952/2018 [07:23<00:15,  4.40it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1954/2018 [07:23<00:14,  4.40it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.41it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.42it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1968/2018 [07:24<00:11,  4.42it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.43it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.44it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.44it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1982/2018 [07:25<00:08,  4.45it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.45it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.46it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.46it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 1996/2018 [07:26<00:04,  4.47it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 1998/2018 [07:26<00:04,  4.47it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.48it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.49it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|█████████▉| 2010/2018 [07:27<00:01,  4.49it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|█████████▉| 2012/2018 [07:27<00:01,  4.49it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.50it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0133, val_f1w=0.988]\n",
      "Epoch 4: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 4: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0171, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 9584: avg_val_f1w reached 0.99340 (best 0.99340), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/EffB7-Focal-Sampler-epoch=4-val_loss=0.01-avg_val_f1w=0.99.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.000526, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]Epoch     6: adjusting learning rate of group 0 to 3.4615e-05.\n",
      "Epoch 5:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0135, val_f1w=0.993]\n",
      "Epoch 5: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 5: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.000535, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 11501: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993] Epoch     7: adjusting learning rate of group 0 to 2.0690e-05.\n",
      "Epoch 6:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.34it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0113, val_f1w=0.993]\n",
      "Epoch 6: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 6: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.00309, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 13418: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.000591, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]Epoch     8: adjusting learning rate of group 0 to 9.6396e-06.\n",
      "Epoch 7:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1934/2018 [07:23<00:19,  4.37it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.37it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1948/2018 [07:24<00:15,  4.39it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1962/2018 [07:25<00:12,  4.41it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.41it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1976/2018 [07:26<00:09,  4.43it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▊| 1990/2018 [07:27<00:06,  4.45it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.45it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 2004/2018 [07:28<00:03,  4.47it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.0112, val_f1w=0.993]\n",
      "Epoch 7: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 7: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000588, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 15335: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]  Epoch     9: adjusting learning rate of group 0 to 2.5447e-06.\n",
      "Epoch 8:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.36it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1938/2018 [07:22<00:18,  4.37it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.39it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1952/2018 [07:23<00:15,  4.40it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.41it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.42it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.44it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.45it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.46it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.46it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.48it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.49it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.00996, val_f1w=0.993]\n",
      "Epoch 8: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993] \n",
      "Epoch 8: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0121, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 17252: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.000395, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]Epoch    10: adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 9:  95%|█████████▌| 1918/2018 [07:22<00:23,  4.34it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.34it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.35it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1932/2018 [07:23<00:19,  4.36it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1934/2018 [07:23<00:19,  4.36it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.37it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  96%|█████████▋| 1946/2018 [07:24<00:16,  4.38it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1948/2018 [07:24<00:15,  4.38it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.39it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1960/2018 [07:25<00:13,  4.40it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1962/2018 [07:25<00:12,  4.41it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.41it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1974/2018 [07:26<00:09,  4.42it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1976/2018 [07:26<00:09,  4.43it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.43it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.44it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▊| 1988/2018 [07:27<00:06,  4.45it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▊| 1990/2018 [07:27<00:06,  4.45it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.45it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.46it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 2002/2018 [07:28<00:03,  4.47it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 2004/2018 [07:28<00:03,  4.47it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.47it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.48it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|█████████▉| 2016/2018 [07:29<00:00,  4.49it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.0111, val_f1w=0.993]\n",
      "Epoch 9: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 9: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000218, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 19169: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991] Epoch    11: adjusting learning rate of group 0 to 9.7555e-05.\n",
      "Epoch 10:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1934/2018 [07:23<00:19,  4.37it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.37it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1948/2018 [07:24<00:15,  4.39it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1962/2018 [07:25<00:12,  4.41it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.41it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1976/2018 [07:26<00:09,  4.43it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▊| 1990/2018 [07:27<00:06,  4.45it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.45it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 2004/2018 [07:28<00:03,  4.47it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.00887, val_f1w=0.991]\n",
      "Epoch 10: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.0153, val_f1w=0.976] \n",
      "Epoch 10: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.0141, v_num=1666580, train_F1w=1.000, val_loss=0.0153, val_f1w=0.976]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 21086: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.02, v_num=1666580, train_F1w=1.000, val_loss=0.0153, val_f1w=0.976]   Epoch    12: adjusting learning rate of group 0 to 9.0460e-05.\n",
      "Epoch 11:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.34it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0153, val_f1w=0.976]\n",
      "Epoch 11: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 11: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.0219, v_num=1666580, train_F1w=0.667, val_loss=0.0204, val_f1w=0.979]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 23003: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0103, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]  Epoch    13: adjusting learning rate of group 0 to 7.9410e-05.\n",
      "Epoch 12:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.36it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.37it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.39it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1952/2018 [07:23<00:15,  4.40it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.41it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.41it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  97%|█████████▋| 1966/2018 [07:24<00:11,  4.42it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1980/2018 [07:25<00:08,  4.44it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.45it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 1994/2018 [07:26<00:05,  4.46it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|█████████▉| 2008/2018 [07:27<00:02,  4.48it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.49it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0204, val_f1w=0.979]\n",
      "Epoch 12: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 12: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.0104, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 24920: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.00132, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988] Epoch    14: adjusting learning rate of group 0 to 6.5485e-05.\n",
      "Epoch 13:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.34it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0124, val_f1w=0.988]\n",
      "Epoch 13: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 13: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00128, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 26837: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.00291, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989] Epoch    15: adjusting learning rate of group 0 to 5.0050e-05.\n",
      "Epoch 14:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0109, val_f1w=0.989]\n",
      "Epoch 14: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 14: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.00298, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 28754: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.0095, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]  Epoch    16: adjusting learning rate of group 0 to 3.4615e-05.\n",
      "Epoch 15:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0139, val_f1w=0.993]\n",
      "Epoch 15: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 15: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=0.00953, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 30671: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=3.17e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]Epoch    17: adjusting learning rate of group 0 to 2.0690e-05.\n",
      "Epoch 16:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.35it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  95%|█████████▌| 1922/2018 [07:21<00:22,  4.35it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1936/2018 [07:22<00:18,  4.37it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1950/2018 [07:23<00:15,  4.39it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.40it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1964/2018 [07:24<00:12,  4.41it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1978/2018 [07:25<00:09,  4.44it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▊| 1992/2018 [07:26<00:05,  4.46it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.47it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.48it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16:  99%|█████████▉| 2006/2018 [07:27<00:02,  4.48it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0318, val_f1w=0.985]\n",
      "Epoch 16: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 16: 100%|██████████| 2018/2018 [07:28<00:00,  4.50it/s, loss=2.99e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 32588: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=0.000962, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]Epoch    18: adjusting learning rate of group 0 to 9.6396e-06.\n",
      "Epoch 17:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1934/2018 [07:23<00:19,  4.37it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.37it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.38it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1948/2018 [07:24<00:15,  4.39it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1962/2018 [07:25<00:12,  4.41it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.41it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1976/2018 [07:26<00:09,  4.43it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▊| 1990/2018 [07:27<00:06,  4.45it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.45it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 2004/2018 [07:28<00:03,  4.47it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.0126, val_f1w=0.993]\n",
      "Epoch 17: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993] \n",
      "Epoch 17: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=0.000986, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 34505: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]Epoch    19: adjusting learning rate of group 0 to 2.5447e-06.\n",
      "Epoch 18:  95%|█████████▌| 1918/2018 [07:21<00:23,  4.34it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  95%|█████████▌| 1920/2018 [07:21<00:22,  4.34it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.35it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.36it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1930/2018 [07:22<00:20,  4.36it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1932/2018 [07:22<00:19,  4.36it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1934/2018 [07:22<00:19,  4.37it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.38it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  96%|█████████▋| 1946/2018 [07:23<00:16,  4.39it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1948/2018 [07:23<00:15,  4.39it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.40it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1960/2018 [07:24<00:13,  4.41it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1962/2018 [07:24<00:12,  4.41it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.42it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.43it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1974/2018 [07:25<00:09,  4.43it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1976/2018 [07:25<00:09,  4.43it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.44it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.45it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▊| 1988/2018 [07:26<00:06,  4.45it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▊| 1990/2018 [07:26<00:06,  4.45it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.46it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.47it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 2002/2018 [07:27<00:03,  4.47it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 2004/2018 [07:27<00:03,  4.47it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.48it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.49it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|█████████▉| 2016/2018 [07:28<00:00,  4.49it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.015, val_f1w=0.993]\n",
      "Epoch 18: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 18: 100%|██████████| 2018/2018 [07:28<00:00,  4.49it/s, loss=3.88e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 36422: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  95%|█████████▍| 1916/2018 [07:21<00:23,  4.34it/s, loss=9.66e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]Epoch    20: adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 19:  95%|█████████▌| 1918/2018 [07:22<00:23,  4.34it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  95%|█████████▌| 1920/2018 [07:22<00:22,  4.34it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  95%|█████████▌| 1922/2018 [07:22<00:22,  4.34it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  95%|█████████▌| 1924/2018 [07:22<00:21,  4.35it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  95%|█████████▌| 1926/2018 [07:22<00:21,  4.35it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1928/2018 [07:22<00:20,  4.35it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1930/2018 [07:23<00:20,  4.36it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1932/2018 [07:23<00:19,  4.36it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1934/2018 [07:23<00:19,  4.36it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1936/2018 [07:23<00:18,  4.37it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1938/2018 [07:23<00:18,  4.37it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1940/2018 [07:23<00:17,  4.37it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▌| 1942/2018 [07:23<00:17,  4.38it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▋| 1944/2018 [07:23<00:16,  4.38it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  96%|█████████▋| 1946/2018 [07:24<00:16,  4.38it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1948/2018 [07:24<00:15,  4.38it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1950/2018 [07:24<00:15,  4.39it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1952/2018 [07:24<00:15,  4.39it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1954/2018 [07:24<00:14,  4.39it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1956/2018 [07:24<00:14,  4.40it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1958/2018 [07:24<00:13,  4.40it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1960/2018 [07:25<00:13,  4.40it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1962/2018 [07:25<00:12,  4.41it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1964/2018 [07:25<00:12,  4.41it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  97%|█████████▋| 1966/2018 [07:25<00:11,  4.41it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1968/2018 [07:25<00:11,  4.42it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1970/2018 [07:25<00:10,  4.42it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1972/2018 [07:25<00:10,  4.42it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1974/2018 [07:26<00:09,  4.42it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1976/2018 [07:26<00:09,  4.43it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1978/2018 [07:26<00:09,  4.43it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1980/2018 [07:26<00:08,  4.43it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1982/2018 [07:26<00:08,  4.44it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1984/2018 [07:26<00:07,  4.44it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  98%|█████████▊| 1986/2018 [07:26<00:07,  4.44it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▊| 1988/2018 [07:27<00:06,  4.45it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▊| 1990/2018 [07:27<00:06,  4.45it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▊| 1992/2018 [07:27<00:05,  4.45it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 1994/2018 [07:27<00:05,  4.46it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 1996/2018 [07:27<00:04,  4.46it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 1998/2018 [07:27<00:04,  4.46it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 2000/2018 [07:27<00:04,  4.46it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 2002/2018 [07:28<00:03,  4.47it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 2004/2018 [07:28<00:03,  4.47it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19:  99%|█████████▉| 2006/2018 [07:28<00:02,  4.47it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|█████████▉| 2008/2018 [07:28<00:02,  4.48it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|█████████▉| 2010/2018 [07:28<00:01,  4.48it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|█████████▉| 2012/2018 [07:28<00:01,  4.48it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|█████████▉| 2014/2018 [07:28<00:00,  4.49it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|█████████▉| 2016/2018 [07:29<00:00,  4.49it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0128, val_f1w=0.992]\n",
      "Epoch 19: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0107, val_f1w=0.992]\n",
      "Epoch 19: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0107, val_f1w=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 38339: avg_val_f1w was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2018/2018 [07:29<00:00,  4.49it/s, loss=9.67e-05, v_num=1666580, train_F1w=1.000, val_loss=0.0107, val_f1w=0.992]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath='/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/', \n",
    "                                      filename='EffB7-Focal-Sampler-{epoch}-{val_loss:.2f}-{avg_val_f1w:.2f}',\n",
    "                                      monitor='avg_val_f1w',\n",
    "                                      verbose=True,\n",
    "                                      save_last=None,\n",
    "                                      save_top_k=1,\n",
    "                                      save_weights_only=False,\n",
    "                                      mode='max',\n",
    "                                      auto_insert_metric_name=True,\n",
    "                                      )\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor='EarlyStop_Log',\\\n",
    "                                    min_delta=0.00,\\\n",
    "                                    patience=5,\\\n",
    "                                    verbose=False,\\\n",
    "                                    mode='min')\n",
    "    \n",
    "\n",
    "## Sanity-check\n",
    "trainer = pl.Trainer(gpus=gpu,\n",
    "                     callbacks=[checkpoint_callback,\n",
    "                                # early_stop_callback,\n",
    "                               ],\n",
    "                    #  deterministic=True,\n",
    "                     enable_progress_bar=True,\n",
    "                    #  progress_bar_\n",
    "                    #  limit_train_batches=2,\n",
    "                    #  limit_val_batches=2,\n",
    "                     max_epochs=20)\n",
    "\n",
    "# Then you call the fit method passing the PL-module and PL-Datamodule, to start training.\n",
    "trainer.fit(eff_model_focal_sampler, dm)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e4dfc25-d131-4ca6-925a-b88f3ef119af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Pinus       0.84      0.93      0.88        28\n",
      "               Erica.m       0.82      1.00      0.90       184\n",
      "             Cistus sp       0.88      0.86      0.87        69\n",
      "             Lavandula       0.95      0.81      0.88        74\n",
      "             Citrus sp       0.35      0.94      0.51        53\n",
      "     Helianthus annuus       0.99      0.91      0.95        91\n",
      "        Eucalyptus sp.       1.00      0.61      0.76        95\n",
      "Rosmarinus officinalis       0.89      0.77      0.82        52\n",
      "              Brassica       1.00      0.48      0.65       140\n",
      "                Cardus       0.50      0.63      0.56        19\n",
      "                 Tilia       0.95      0.90      0.92        67\n",
      "             Taraxacum       0.89      0.96      0.92        25\n",
      "\n",
      "              accuracy                           0.81       897\n",
      "             macro avg       0.84      0.82      0.80       897\n",
      "          weighted avg       0.88      0.81      0.81       897\n",
      "\n",
      "CPU times: user 40.8 s, sys: 242 ms, total: 41 s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"EffB7-Focal-Sampler-epoch=4-val_loss=0.01-avg_val_f1w=0.99.ckpt\"\n",
    "baseline_model  = LitModel_Focal(model=eff_model)\n",
    "# Epoch 4, global step 9584: avg_val_f1w reached 0.99340 (best 0.99340), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/EffB7-Focal-Sampler-epoch=4-val_loss=0.01-avg_val_f1w=0.99.ckpt\" as top 1\n",
    "\n",
    "# Epoch 6, global step 13418: avg_val_f1w reached 0.99340 (best 0.99340), saving model to \"/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/\" as top 1\n",
    "\n",
    "# /mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/Base-epoch=7-val_loss=0.06-avg_val_f1w=0.98.ckpt\n",
    "# baseline_model.model.load_from_checkpoint('/content/drive/MyDrive/dataset_honey/results/'+ model_name)\n",
    "\n",
    "checkpoint =  torch.load('/mnt/gpid08/datasets/remote_sensing/tmp_from_gpid07/honey/results/'+ model_name)\n",
    "\n",
    "baseline_model.load_state_dict(checkpoint['state_dict'])\n",
    "# baseline_model.load_from_checkpoint(\"Base-epoch=1-val_loss=0.05-avg_val_f1w=0.98.ckpt\")\n",
    "\n",
    "targets, preds, pred_score = [],[],[]\n",
    "baseline_model.to('cuda')\n",
    "for ii, data in enumerate(dm.test_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        targets.append(data['target'].numpy()) #torch.argmax(data['target'],dim=1).numpy()\n",
    "        # y = y.reshape((-1,1))\n",
    "        # print(y.shape)\n",
    "        ## inference\n",
    "        o = baseline_model.predict(data['image'].to('cuda'))\n",
    "        o1 = torch.argmax(o, axis=1).cpu().numpy()\n",
    "        # print(o.shape)\n",
    "        preds.append(o1)\n",
    "        pred_score.append(torch.softmax(o,axis=1))\n",
    "        # print(y)\n",
    "        # print(o)\n",
    "        # if ii==2:\n",
    "        #   break\n",
    "# print(ii)\n",
    "preds2 = np.vstack([x for x in preds]).reshape(-1,1)\n",
    "targets2 = np.vstack([x for x in targets]).reshape(-1,1)\n",
    "pred_score2 = np.vstack([x.cpu().numpy() for x in pred_score]).reshape(-1,12)\n",
    "\n",
    "target_names = ['Pinus','Erica.m', 'Cistus sp', 'Lavandula', 'Citrus sp', 'Helianthus annuus',\n",
    "          'Eucalyptus sp.', 'Rosmarinus officinalis', 'Brassica', 'Cardus', 'Tilia', 'Taraxacum']\n",
    "\n",
    "print(classification_report(targets2, preds2, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88966c80-a51b-43a6-a1d9-652f6bc4a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(897, 12)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score2 = np.vstack([x.cpu().numpy() for x in pred_score]).reshape(-1,12)\n",
    "pred_score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3321164c-1d12-4739-aafc-30053cb9edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cb1a589-3ac8-46fe-a1a7-5441bb9a0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862578746985253"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(targets2[:,0], pred_score2, multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "784a8eea-4efa-467b-934d-c434880d6f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897370899034885"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(targets2[:,0], pred_score2, multi_class='ovr', average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edec550e-7d02-4dc8-b388-2a7f4540678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868717358461957"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(targets2[:,0], pred_score2, multi_class='ovo', average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e669d727-00db-451a-a562-77dd6ffd1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60538e34-c268-4281-ab7c-5a19b230be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets2, preds2, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc9bb3e3-e1e9-4764-b864-412553c5b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44ee8fdf-5b22-4e1a-921c-773d2cf2927c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normalized (rows) Confusion Matrix')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cm, annot=True, fmt='.1f')\n",
    "plt.title('Normalized (rows) Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ed79926-1f1e-458e-950a-9312e2fd370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normalized (pred) Confusion Matrix')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(targets2, preds2, normalize='pred')\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cm, annot=True, fmt='.1f')\n",
    "plt.title('Normalized (pred) Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1731d-408e-474d-b0b1-82f00bb2a315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
